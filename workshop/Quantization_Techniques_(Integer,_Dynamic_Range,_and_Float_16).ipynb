{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Required Packages\n",
        "\n",
        "### Note: Resolving `keras.src` Namespace Issue\n",
        "When using TensorFlow and TensorFlow Model Optimization in Colab, you may encounter a `keras.src` namespace issue, causing incompatibility with `tensorflow_model_optimization.quantization.keras`. To resolve this:\n",
        "\n",
        "1. Set the `KERAS_BACKEND` environment variable to `tensorflow` before importing TensorFlow.\n",
        "2. Ensure you are using compatible versions of TensorFlow (`>=2.12`) and TensorFlow Model Optimization.\n",
        "3. Clone the model using `tensorflow.keras.models.clone_model()` to ensure it aligns with the `tensorflow.keras` namespace.\n",
        "4. Always restart the runtime and reinstall TensorFlow-related packages to avoid lingering conflicts.\n",
        "\n",
        "This ensures that all operations use the correct `tensorflow.keras` implementation, avoiding compatibility issues.\n"
      ],
      "metadata": {
        "id": "U3RedTg8873J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y keras tensorflow tensorflow-model-optimization\n",
        "!pip install tensorflow==2.12 tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ynbwI56t9ceO",
        "outputId": "4f253291-5283-4003-94a3-0199833a6c2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 3.5.0\n",
            "Uninstalling keras-3.5.0:\n",
            "  Successfully uninstalled keras-3.5.0\n",
            "Found existing installation: tensorflow 2.17.1\n",
            "Uninstalling tensorflow-2.17.1:\n",
            "  Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[33mWARNING: Skipping tensorflow-model-optimization as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.68.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.12.1)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.33)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.36,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.36-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, numpy, keras, gast, tensorflow-model-optimization, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.0\n",
            "    Uninstalling wrapt-1.17.0:\n",
            "      Successfully uninstalled wrapt-1.17.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.27.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-model-optimization-0.8.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "be191fdba75646f8a1897385964ecfea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "CFEj5v-J9pPz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I:  Post Training Quantization (PTQ) - Integer, Dynamic Range, and Float 16\n",
        "First part of this notebook demonstrates three types of post-training quantization for a CNN model trained on the MNIST dataset. Quantization is a model compression technique that reduces model size and computational requirements, enabling efficient deployment on resource-constrained devices.\n",
        "\n",
        "## Goals:\n",
        "1. Train a CNN model on the MNIST dataset.\n",
        "2. Apply three quantization techniques:\n",
        "   - Integer Quantization\n",
        "   - Dynamic Range Quantization\n",
        "   - Float 16 Quantization\n",
        "3. Compare the quantized models in terms of size and accuracy.\n"
      ],
      "metadata": {
        "id": "omSnTckQoK9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation\n",
        "We use the MNIST dataset, which contains grayscale images of handwritten digits (0-9).\n",
        "1. Normalize the pixel values to the range [0, 1].\n",
        "2. Reshape the data for input into the CNN model.\n",
        "3. One-hot encode the labels for classification.\n"
      ],
      "metadata": {
        "id": "oSVayjgGoaUu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF3L0T0CoJco",
        "outputId": "4e7cd858-806e-476c-aad3-d8f2505160e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Training data shape: (60000, 28, 28, 1), Labels shape: (60000, 10)\n",
            "Test data shape: (10000, 28, 28, 1), Labels shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# Reshape the data for CNN input\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(f\"Training data shape: {x_train.shape}, Labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}, Labels shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Simple CNN\n",
        "We build a Convolutional Neural Network (CNN) with the following layers:\n",
        "1. **Convolutional Layer**: Extracts features from the input images.\n",
        "2. **MaxPooling Layer**: Reduces spatial dimensions, lowering computational requirements.\n",
        "3. **Flatten Layer**: Converts the 2D feature maps into a 1D vector.\n",
        "4. **Dense Layers**: Fully connected layers for classification.\n",
        "\n",
        "The model is compiled using the Adam optimizer and trained for 2 epochs.\n"
      ],
      "metadata": {
        "id": "oF0-Yeerolqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple CNN model\n",
        "def create_cnn_model():\n",
        "    inputs = Input(shape=(28, 28, 1))\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Compile and train the model\n",
        "model = create_cnn_model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=2, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the trained model\n",
        "original_accuracy = model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "print(f\"Original Model Accuracy: {original_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ccszLiRovPM",
        "outputId": "84ccf0bf-4c68-4c25-ddba-3b40425b36df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.1520 - accuracy: 0.9542 - val_loss: 0.0572 - val_accuracy: 0.9811\n",
            "Epoch 2/2\n",
            "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0519 - accuracy: 0.9844 - val_loss: 0.0558 - val_accuracy: 0.9811\n",
            "Original Model Accuracy: 0.9811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Quantization Techniques\n",
        "We apply three types of post-training quantization to the trained CNN model:\n",
        "1. **Integer Quantization**: Converts both weights and activations to 8-bit integers.\n",
        "2. **Dynamic Range Quantization**: Reduces the precision of weights while keeping activations in floating-point format.\n",
        "3. **Float 16 Quantization**: Converts both weights and activations to 16-bit floating-point values.\n"
      ],
      "metadata": {
        "id": "b81MxPHmpnCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the trained model to TensorFlow Lite format without quantization (baseline)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the baseline TFLite model\n",
        "with open(\"model_baseline.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Integer Quantization\n",
        "def representative_data_gen():\n",
        "    for input_value in x_test[:100]:  # Use a subset of the test set\n",
        "        # Yield a dictionary where the key matches the model's input tensor name\n",
        "        yield [input_value.reshape(1, 28, 28, 1).astype(\"float32\")]\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen  # Corrected function\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "tflite_model_int8 = converter.convert()\n",
        "\n",
        "# Save the Integer Quantization model\n",
        "with open(\"model_integer_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model_int8)\n",
        "\n",
        "# Dynamic Range Quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model_dynamic = converter.convert()\n",
        "\n",
        "# Save the Dynamic Range Quantization model\n",
        "with open(\"model_dynamic_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model_dynamic)\n",
        "\n",
        "# Float 16 Quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # Ensure fresh converter\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]  # Correctly set for Float16 quantization\n",
        "tflite_model_float16 = converter.convert()\n",
        "\n",
        "# Save the Float 16 Quantization model\n",
        "with open(\"model_float16_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model_float16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbW9QzgOpwb5",
        "outputId": "3a34142b-6c9e-4997-ae5d-64bee8ad9ce7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Model Sizes and Accuracy\n",
        "We compare the quantized models in terms of:\n",
        "1. **Model Size**: Smaller models are better suited for resource-constrained devices.\n",
        "2. **Accuracy**: Quantization should preserve the original model’s accuracy as much as possible.\n"
      ],
      "metadata": {
        "id": "Bgr-nMzxsktu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Compare model sizes\n",
        "model_files = [\n",
        "    \"model_baseline.tflite\",\n",
        "    \"model_integer_quant.tflite\",\n",
        "    \"model_dynamic_quant.tflite\",\n",
        "    \"model_float16_quant.tflite\"\n",
        "]\n",
        "\n",
        "print(\"Model Sizes (KB):\")\n",
        "for file in model_files:\n",
        "    print(f\"{file}: {os.path.getsize(file) / 1024:.2f} KB\")\n",
        "\n",
        "# Evaluate accuracy for quantized models\n",
        "def evaluate_tflite_model(tflite_model_path):\n",
        "    # Load the TFLite model\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    # Evaluate on test set\n",
        "    correct_predictions = 0\n",
        "    for i in range(len(x_test)):\n",
        "        input_data = x_test[i:i+1].astype(\"float32\")\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "        if tf.argmax(output_data, axis=1) == tf.argmax(y_test[i:i+1], axis=1):\n",
        "            correct_predictions += 1\n",
        "\n",
        "    return correct_predictions / len(x_test)\n",
        "\n",
        "print(\"\\nModel Accuracies:\")\n",
        "print(f\"Baseline: {original_accuracy:.4f}\")\n",
        "print(f\"Integer Quantization: {evaluate_tflite_model('model_integer_quant.tflite'):.4f}\")\n",
        "print(f\"Dynamic Range Quantization: {evaluate_tflite_model('model_dynamic_quant.tflite'):.4f}\")\n",
        "print(f\"Float 16 Quantization: {evaluate_tflite_model('model_float16_quant.tflite'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VzFgSfSsk7x",
        "outputId": "7459e086-30d6-4bd1-ea8b-2b804be0680d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Sizes (KB):\n",
            "model_baseline.tflite: 2713.34 KB\n",
            "model_integer_quant.tflite: 682.25 KB\n",
            "model_dynamic_quant.tflite: 682.25 KB\n",
            "model_float16_quant.tflite: 1358.77 KB\n",
            "\n",
            "Model Accuracies:\n",
            "Baseline: 0.9843\n",
            "Integer Quantization: 0.9842\n",
            "Dynamic Range Quantization: 0.9842\n",
            "Float 16 Quantization: 0.9843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part I Summary\n",
        "Quantization significantly reduces model size while maintaining comparable accuracy. Key observations:\n",
        "- Integer Quantization provides the smallest model size and computation complexity but may slightly reduce accuracy.\n",
        "- Dynamic Range Quantization balances size, computation complexity, and performance.\n",
        "- Float 16 Quantization retains higher accuracy with moderate size and computation complexity reduction.\n"
      ],
      "metadata": {
        "id": "YSdtfn0tw4Wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Quantization-Aware Training (QAT) - Integer and Dynamic Range\n",
        "Quantization-Aware Training is a technique where integer quantization is simulated during the training process. This allows the model to adjust its weights and activations, minimizing the accuracy loss caused by quantization.\n",
        "\n",
        "In this step, we:\n",
        "1. Prepare a quantization-aware model using TensorFlow’s `QuantizeWrapper`.\n",
        "2. Train the model on MNIST with quantization simulation.\n",
        "3. Convert the model to TensorFlow Lite format for Integer and Dynamic Range.\n",
        "4. Compare model sizes and accuracy after QAT.\n"
      ],
      "metadata": {
        "id": "iJ53VME51G6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the model type\n",
        "model = create_cnn_model()\n",
        "print(f\"Model type: {type(model)}\")\n",
        "\n",
        "from tensorflow_model_optimization.quantization.keras import quantize_model\n",
        "\n",
        "# Prepare the quantization-aware model\n",
        "qat_model = quantize_model(create_cnn_model())\n",
        "\n",
        "# Compile the QAT model\n",
        "qat_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the QAT model\n",
        "print(\"Training the QAT Model...\")\n",
        "qat_history = qat_model.fit(x_train, y_train, epochs=2, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the QAT-trained model\n",
        "qat_accuracy = qat_model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "print(f\"QAT Model Accuracy: {qat_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV7GtpH9_RNK",
        "outputId": "0bf6dd9e-6002-40f9-88b1-57f467ef5f01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model type: <class 'keras.engine.functional.Functional'>\n",
            "Training the QAT Model...\n",
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 72s 37ms/step - loss: 0.1504 - accuracy: 0.9564 - val_loss: 0.0594 - val_accuracy: 0.9806\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0527 - accuracy: 0.9842 - val_loss: 0.0497 - val_accuracy: 0.9838\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0474 - val_accuracy: 0.9849\n",
            "QAT Model Accuracy: 0.9849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Quantization After QAT\n",
        "We now convert the QAT-trained model to TensorFlow Lite format and apply three quantization techniques:\n",
        "1. **Integer Quantization**\n",
        "2. **Dynamic Range Quantization**\n"
      ],
      "metadata": {
        "id": "cDLPWBrQBsZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the QAT-trained model to TensorFlow Lite\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "\n",
        "# Integer Quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen  # Use the same representative data generator\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "tflite_model_qat_int8 = converter.convert()\n",
        "\n",
        "# Save Integer Quantization model\n",
        "with open(\"qat_model_integer_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model_qat_int8)\n",
        "\n",
        "# Dynamic Range Quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model_qat_dynamic = converter.convert()\n",
        "\n",
        "# Save Dynamic Range Quantization model\n",
        "with open(\"qat_model_dynamic_quant.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model_qat_dynamic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8kYLIiB3K6",
        "outputId": "7b533868-4e0e-430e-a670-2d8b109ba2d2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_3_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, flatten_3_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_3_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, flatten_3_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Model Sizes and Accuracy\n",
        "We compare the model sizes and accuracy for the quantized QAT-trained models.\n"
      ],
      "metadata": {
        "id": "eVaR7rd52RG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model sizes\n",
        "model_files = [\n",
        "    \"qat_model_integer_quant.tflite\",\n",
        "    \"qat_model_dynamic_quant.tflite\",\n",
        "]\n",
        "\n",
        "print(\"\\nModel Sizes After QAT (KB):\")\n",
        "for file in model_files:\n",
        "    print(f\"{file}: {os.path.getsize(file) / 1024:.2f} KB\")\n",
        "\n",
        "# Evaluate accuracy for QAT-quantized models\n",
        "print(\"\\nModel Accuracies After QAT:\")\n",
        "print(f\"QAT Baseline Model Accuracy: {qat_accuracy:.4f}\")\n",
        "print(f\"Integer Quantization: {evaluate_tflite_model('qat_model_integer_quant.tflite'):.4f}\")\n",
        "print(f\"Dynamic Range Quantization: {evaluate_tflite_model('qat_model_dynamic_quant.tflite'):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nfH8mJLDPYv",
        "outputId": "20246b7f-0717-4844-aead-180919c8435b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Sizes After QAT (KB):\n",
            "qat_model_integer_quant.tflite: 682.84 KB\n",
            "qat_model_dynamic_quant.tflite: 682.84 KB\n",
            "\n",
            "Model Accuracies After QAT:\n",
            "QAT Baseline Model Accuracy: 0.9849\n",
            "Integer Quantization: 0.9849\n",
            "Dynamic Range Quantization: 0.9849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II Summary\n",
        "Quantization-Aware Training (QAT) significantly reduces accuracy loss caused by quantization. Key observations:\n",
        "- QAT improves the accuracy of quantized models, making it suitable for resource-constrained deployments that demands the high precision/accuracy.\n",
        "- QAT is incompatible with Float16 quantization because they target fundamentally different quantization formats.\n"
      ],
      "metadata": {
        "id": "d3EG8r-e2L-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vu76ZeuoFaZV"
      }
    }
  ]
}