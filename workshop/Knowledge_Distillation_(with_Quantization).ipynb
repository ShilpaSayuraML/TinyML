{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Distillation (with Quantization)\n",
        "Knowledge Distillation (KD) is a technique where a smaller model (student) is trained to mimic a larger, pre-trained model (teacher). The student learns from the teacher's output probabilities (soft labels) rather than the hard ground-truth labels.\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. Training a teacher model on the MNIST dataset.\n",
        "2. Training a smaller student model using KD.\n",
        "3. Applying full integer quantization to the student model.\n",
        "4. Comparing model sizes and accuracies of:\n",
        "   - Teacher Model\n",
        "   - Student Model\n",
        "   - Quantized Student Model\n"
      ],
      "metadata": {
        "id": "9suAf8kTn2EK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFG3Fsz5nzyL",
        "outputId": "347c5367-6a82-42d1-c2a4-2877d3df4a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training data shape: (60000, 28, 28, 1), Labels shape: (60000, 10)\n",
            "Test data shape: (10000, 28, 28, 1), Labels shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(f\"Training data shape: {x_train.shape}, Labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}, Labels shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the teacher model\n",
        "def create_teacher_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile and train the teacher model\n",
        "teacher_model = create_teacher_model()\n",
        "teacher_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "teacher_model.fit(x_train, y_train, epochs=2, batch_size=32, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the teacher model\n",
        "teacher_accuracy = teacher_model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "print(f\"Teacher Model Accuracy: {teacher_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58iliarBoDri",
        "outputId": "97b9f10c-a644-46d0-fab1-9be9d43c27ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 27ms/step - accuracy: 0.9124 - loss: 0.2993 - val_accuracy: 0.9780 - val_loss: 0.0675\n",
            "Epoch 2/2\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 23ms/step - accuracy: 0.9842 - loss: 0.0525 - val_accuracy: 0.9824 - val_loss: 0.0497\n",
            "Teacher Model Accuracy: 0.9824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Knowledge Distillation\n",
        "The student model is trained using Knowledge Distillation. Instead of directly using the ground-truth labels, the student learns from the teacher's output probabilities (soft labels) using the Kullback-Leibler (KL) divergence.\n"
      ],
      "metadata": {
        "id": "bPrm0bqEo0a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the student model\n",
        "def create_student_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "student_model = create_student_model()\n",
        "\n",
        "# Precompute teacher predictions (soft labels)\n",
        "temperature = 5\n",
        "teacher_soft_labels = teacher_model.predict(x_train, batch_size=32) / temperature\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Combine ground-truth labels and teacher soft labels\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, teacher_soft_labels)).batch(32)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVMU7Svto1Wr",
        "outputId": "8390942d-2652-4d99-8e38-94f4931695fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Knowledge Distillation Loss\n",
        "def kd_loss(y_true, y_pred, soft_labels, temperature=5):\n",
        "    # Hard label loss (ground truth)\n",
        "    hard_loss = tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred)\n",
        "\n",
        "    # Soft label loss (teacher predictions for the batch)\n",
        "    soft_loss = tf.keras.losses.KLDivergence()(\n",
        "        tf.nn.softmax(soft_labels / temperature),\n",
        "        tf.nn.softmax(y_pred / temperature)\n",
        "    )\n",
        "\n",
        "    # Combine the losses\n",
        "    return 0.5 * hard_loss + 0.5 * soft_loss\n",
        "\n",
        "# Compile the student model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "accuracy_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "for epoch in range(2):  # Number of epochs\n",
        "    print(f\"Epoch {epoch + 1}/2\")\n",
        "    for step, (x_batch, y_batch, soft_labels) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            y_pred = student_model(x_batch, training=True)\n",
        "            loss = kd_loss(y_batch, y_pred, soft_labels)\n",
        "\n",
        "        # Backward pass\n",
        "        grads = tape.gradient(loss, student_model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, student_model.trainable_weights))\n",
        "\n",
        "        # Update the accuracy metric\n",
        "        accuracy_metric.update_state(y_batch, y_pred)\n",
        "\n",
        "        # Log progress\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}: Loss = {loss.numpy():.4f}, Accuracy = {accuracy_metric.result().numpy():.4f}\")\n",
        "\n",
        "    # Reset metrics at the end of each epoch\n",
        "    accuracy_metric.reset_state()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-0Ge2NMsgWt",
        "outputId": "70b09e9d-6e07-45db-eec7-645c07b8c395"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "Step 0: Loss = 1.1550, Accuracy = 0.0625\n",
            "Step 100: Loss = 0.1858, Accuracy = 0.7816\n",
            "Step 200: Loss = 0.1939, Accuracy = 0.8464\n",
            "Step 300: Loss = 0.1157, Accuracy = 0.8635\n",
            "Step 400: Loss = 0.0758, Accuracy = 0.8787\n",
            "Step 500: Loss = 0.1386, Accuracy = 0.8878\n",
            "Step 600: Loss = 0.0476, Accuracy = 0.8982\n",
            "Step 700: Loss = 0.0370, Accuracy = 0.9064\n",
            "Step 800: Loss = 0.0606, Accuracy = 0.9126\n",
            "Step 900: Loss = 0.0474, Accuracy = 0.9180\n",
            "Step 1000: Loss = 0.1115, Accuracy = 0.9218\n",
            "Step 1100: Loss = 0.0413, Accuracy = 0.9255\n",
            "Step 1200: Loss = 0.0901, Accuracy = 0.9288\n",
            "Step 1300: Loss = 0.0469, Accuracy = 0.9318\n",
            "Step 1400: Loss = 0.0336, Accuracy = 0.9344\n",
            "Step 1500: Loss = 0.0541, Accuracy = 0.9362\n",
            "Step 1600: Loss = 0.0624, Accuracy = 0.9382\n",
            "Step 1700: Loss = 0.0229, Accuracy = 0.9402\n",
            "Step 1800: Loss = 0.0363, Accuracy = 0.9423\n",
            "Epoch 2/2\n",
            "Step 0: Loss = 0.0494, Accuracy = 0.9688\n",
            "Step 100: Loss = 0.0316, Accuracy = 0.9746\n",
            "Step 200: Loss = 0.0730, Accuracy = 0.9751\n",
            "Step 300: Loss = 0.0167, Accuracy = 0.9747\n",
            "Step 400: Loss = 0.0391, Accuracy = 0.9764\n",
            "Step 500: Loss = 0.0368, Accuracy = 0.9763\n",
            "Step 600: Loss = 0.0089, Accuracy = 0.9775\n",
            "Step 700: Loss = 0.0111, Accuracy = 0.9782\n",
            "Step 800: Loss = 0.0225, Accuracy = 0.9791\n",
            "Step 900: Loss = 0.0195, Accuracy = 0.9792\n",
            "Step 1000: Loss = 0.0347, Accuracy = 0.9798\n",
            "Step 1100: Loss = 0.0178, Accuracy = 0.9801\n",
            "Step 1200: Loss = 0.1106, Accuracy = 0.9803\n",
            "Step 1300: Loss = 0.0324, Accuracy = 0.9804\n",
            "Step 1400: Loss = 0.0167, Accuracy = 0.9807\n",
            "Step 1500: Loss = 0.0443, Accuracy = 0.9806\n",
            "Step 1600: Loss = 0.0640, Accuracy = 0.9808\n",
            "Step 1700: Loss = 0.0041, Accuracy = 0.9808\n",
            "Step 1800: Loss = 0.0127, Accuracy = 0.9810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the student model for evaluation\n",
        "student_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Use standard loss for evaluation\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Evaluate the student model\n",
        "student_accuracy = student_model.evaluate(val_dataset, verbose=0)[1]\n",
        "print(f\"Student Model Accuracy: {student_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aumrYxdUslyd",
        "outputId": "2ccd7c1a-58bc-4780-d77c-08072b6c16a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Model Accuracy: 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Representative dataset generator\n",
        "def representative_data_gen():\n",
        "    for input_value in x_test[:100]:\n",
        "        # Add a batch dimension (convert [28, 28, 1] to [1, 28, 28, 1])\n",
        "        yield [input_value.reshape(1, 28, 28, 1).astype(\"float32\")]\n",
        "\n",
        "\n",
        "# Convert the student model to TensorFlow Lite format with full integer quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(student_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen  # Updated function\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "quantized_student_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open(\"quantized_student_model.tflite\", \"wb\") as f:\n",
        "    f.write(quantized_student_model)\n",
        "print(\"Quantized Student Model saved.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NQDMmvPwX68",
        "outputId": "5d53c724-a958-4205-cd2f-6e500fc66dc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpy1ihoaly'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_6')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133862297658368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862249073824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862249070832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862248627040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862248627392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862248615424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized Student Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Compare model sizes\n",
        "model_files = {\n",
        "    \"Teacher Model\": \"teacher_model.tflite\",\n",
        "    \"Student Model\": \"student_model.tflite\",\n",
        "    \"Quantized Student Model\": \"quantized_student_model.tflite\"\n",
        "}\n",
        "\n",
        "# Save the teacher and student models to TFLite format for size comparison\n",
        "for model_name, model in [(\"teacher_model.tflite\", teacher_model), (\"student_model.tflite\", student_model)]:\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "    with open(model_name, \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "print(\"\\nModel Sizes (KB):\")\n",
        "for name, file in model_files.items():\n",
        "    print(f\"{name}: {os.path.getsize(file) / 1024:.2f} KB\")\n",
        "\n",
        "# Evaluate the quantized student model\n",
        "def evaluate_tflite_model(tflite_model_path):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    correct_predictions = 0\n",
        "    for i in range(len(x_test)):\n",
        "        input_data = x_test[i:i+1].astype(\"float32\")\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "        if np.argmax(output_data) == np.argmax(y_test[i]):\n",
        "            correct_predictions += 1\n",
        "\n",
        "    return correct_predictions / len(x_test)\n",
        "\n",
        "quantized_student_accuracy = evaluate_tflite_model(\"quantized_student_model.tflite\")\n",
        "print(f\"Quantized Student Model Accuracy: {quantized_student_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNcWlvGAw6eY",
        "outputId": "55868d2f-53ef-46d8-daed-82b210076569"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpnr10qpfj'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133862298811232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862298803136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862298809648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862298805776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862298810000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862298570768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved artifact at '/tmp/tmp44hftwxq'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_6')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133862297658368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862249073824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862249070832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862248627040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862248627392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133862248615424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "\n",
            "Model Sizes (KB):\n",
            "Teacher Model: 2713.43 KB\n",
            "Student Model: 682.11 KB\n",
            "Quantized Student Model: 175.62 KB\n",
            "Quantized Student Model Accuracy: 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "- The student model achieves comparable accuracy to the teacher model while being significantly smaller.\n",
        "- Full integer quantization reduces the student model size further, with a slight accuracy drop.\n",
        "- Knowledge Distillation enables smaller models to effectively mimic larger, more complex models.\n"
      ],
      "metadata": {
        "id": "Fe5LLh-z-TXj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Ig81MaKwjnl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}